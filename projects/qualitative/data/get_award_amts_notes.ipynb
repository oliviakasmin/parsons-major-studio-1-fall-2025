{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561e6652",
   "metadata": {},
   "source": [
    "### Extract award amounts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ddc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33c8ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../../quantitative/data/df_grouped_NAID_sorted_title_categories.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb2f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'per month'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search ocrText for phrases, case insensitive. If transcriptionText column is not null, search that instead. Return the percent of row that are not 'non_application' in file_cat that contain the phrases.\n",
    "phrases = ['inscribed on the roll', 'at the rate', 'dollars per month', \"dollars\", \"per annum\", \"on the roll\", \"act of\"]\n",
    "\n",
    "\"on the roll of [place]\"\n",
    "\n",
    "\"scribed on the roll\"\n",
    "\"on the roll\"\n",
    "\"rate of\"\n",
    "\"per month\"\n",
    "\"per annum\"\n",
    "\"commence on the day of\"\n",
    "\"allowance ending\"\n",
    "\"semi anl\"\n",
    "\n",
    "# acts\n",
    "\"act of congress\"\n",
    "\"act of\"\n",
    "\"passed\"\n",
    "\"passed\" + \"act\"\n",
    "\"congress\" + \"act\"\n",
    "\"under the law of\"\n",
    "\n",
    "\"revolutionary claim, act [date]\"\n",
    "\"Certificate of Pension issued the [number] day of [month] [year]\"\n",
    "\n",
    "\"widow of\"\n",
    "\n",
    "# IGNORE AFTER \n",
    "\"arrears\"\n",
    "\n",
    "\"$40 per annum\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f46a8",
   "metadata": {},
   "source": [
    "https://catalog.archives.gov/id/196262530?objectPage=2\n",
    "| **Field**                                            | **Meaning / Context**                                                                                                                                         |\n",
    "| ---------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Ohio 5496**                                        | Pension number or internal file number from the **Wheeling, Ohio Agency** (which covered parts of western Virginia and eastern Ohio).                         |\n",
    "| **Nancy Minor**                                      | The **widow** of **Thomas Minor**, the Revolutionary War soldier.                                                                                             |\n",
    "| **Thomas Minor, decd**                               | “decd” = deceased. Thomas Minor was already a pensioner before his death.                                                                                     |\n",
    "| **Pensioner under the Act of 1818**                  | Thomas originally received a pension under the **Act of March 18, 1818**, which granted pensions to Continental Army veterans who could prove financial need. |\n",
    "| **Died on 11 June 1834**                             | The date of the soldier’s death.                                                                                                                              |\n",
    "| **Jefferson in the State of Ohio**                   | Residence of the widow (Jefferson County, Ohio).                                                                                                              |\n",
    "| **Captain Russell / Col. Scott / Virginia line**     | Indicates Thomas Minor’s service unit — **Virginia Line**, under **Captain Russell** and **Colonel Scott**, for **one year**.                                 |\n",
    "| **Inscribed on the Roll of Wheeling**                | The widow’s name was officially added (“inscribed”) to the **pension roll** at the Wheeling Agency.                                                           |\n",
    "| **Rate: 40 Dollars per annum**                       | The widow received **$40 per year**, reflecting the pension scale set by Congress.                                                                            |\n",
    "| **Commence on 4th March 1836**                       | Payment start date — often standardized for widows under the 1838 Act.                                                                                        |\n",
    "| **Certificate of Pension issued 11 June 1840**       | The date the official pension certificate was issued.                                                                                                         |\n",
    "| **Sent to Hon. Swearingen, H. Reps**                 | The certificate was forwarded to **Hon. Mr. Swearingen**, a **Member of the U.S. House of Representatives**, likely assisting in her application.             |\n",
    "| **Arrears to 4 March 1840: $160.00**                 | Back pay owed from March 1836 through March 1840.                                                                                                             |\n",
    "| **Semi-annual allowance ending 4 Sept 1840: $20.00** | Standard **half-year payment** following the arrears.                                                                                                         |\n",
    "| **Total $180.00**                                    | Total payment due including arrears and current allowance.                                                                                                    |\n",
    "| **Act July 7, 1838**                                 | The **Act of July 7, 1838**, which granted pensions to widows of Revolutionary War soldiers who had been married before the end of the war.                   |\n",
    "| **D. McCurdy / Vol. Page 21**                        | Clerk’s name (**D. McCurdy**) and ledger reference (book and page number).                                                                                    |\n",
    "| **Let 7 July 1840 / R. Sworn**                       | Probably notations for **letter sent** or **sworn affidavit received** on that date.                                                                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e415b",
   "metadata": {},
   "source": [
    "https://catalog.archives.gov/id/53838203?objectPage=27\n",
    "issued August 13, 1833, at $38.32, per annum. from March 4, 1831, under the Act of June 7, 1832, at the Connecticut Agency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bc6e16",
   "metadata": {},
   "source": [
    "BOUNTY LAND WARRANT RECORD CARD\n",
    "ex: https://catalog.archives.gov/id/54686039?objectPage=9\n",
    "\n",
    "form with these fields:\n",
    "\"name\"\n",
    "\"grade\"\n",
    "\"line\"\n",
    "\"warrant number\"\n",
    "\"acreage\"\n",
    "\"issued\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed600ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bount land warrant record card'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"bounty land warrant record card\"\n",
    "\"name\"\n",
    "\"grade\"\n",
    "\"line\"\n",
    "\"warrant number\"\n",
    "\"acreage\"\n",
    "\"issued\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6300125",
   "metadata": {},
   "source": [
    "SOMETIMES THERE IS A REPORT AFTER THE FACT THAT INCLUDES\n",
    "\"four hundred acres of bounty land were issued on April 27, 1810, under Warrant 514\"\n",
    "\"this land was issued by the United States. Land was also issued by the state of Virginia...\"\n",
    "\n",
    "\"under the act of\"\n",
    "\"300 acres of bounty land was issued October 20, 2810\"\n",
    "https://catalog.archives.gov/id/144269084?objectPage=8\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964cacdf",
   "metadata": {},
   "source": [
    "https://catalog.archives.gov/id/54793849?objectPage=5\n",
    "\"400 acres issued the 7th Jany 1832 to\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23098965",
   "metadata": {},
   "source": [
    "\"INVALID.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeeb380",
   "metadata": {},
   "source": [
    "See if this one comes up often\n",
    "https://catalog.archives.gov/id/54534765?objectPage=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f9d62660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cba87c",
   "metadata": {},
   "source": [
    "Filtering\n",
    "- skip if only 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb558e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance on 1000 rows...\n",
      "Time for 1000 rows: 7.22 seconds\n",
      "Estimated time for full dataset: 9.5 minutes\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from functools import lru_cache\n",
    "\n",
    "# Pre-compile regex patterns for better performance\n",
    "PATTERNS = {\n",
    "    'vv_to_w': re.compile(r'\\bvv'),\n",
    "    'digit_1_to_I': re.compile(r'(?<=[A-Za-z])1|1(?=[A-Za-z])'),\n",
    "    'digit_0_to_O': re.compile(r'(?<=[A-Za-z])0|0(?=[A-Za-z])'),\n",
    "    'digit_5_to_S': re.compile(r'(?<=[A-Za-z])5|5(?=[A-Za-z])'),\n",
    "    'digit_8_to_B': re.compile(r'(?<=[A-Za-z])8|8(?=[A-Za-z])'),\n",
    "    'contractions': re.compile(r\"'\\s+([dst])\\b\"),\n",
    "    'hyphenation': re.compile(r'(\\w+)-\\s*\\n\\s*(\\w+)'),\n",
    "    'multiple_spaces': re.compile(r'\\s+'),\n",
    "    'multiple_newlines': re.compile(r'\\n\\s*\\n'),\n",
    "    'sentence_breaks': re.compile(r'([.!?])\\s*\\n+\\s*([A-Z])'),\n",
    "    'space_before_punct': re.compile(r'\\s+([,.!?;:])'),\n",
    "    'space_after_punct': re.compile(r'([,.!?;:])\\s*')\n",
    "}\n",
    "\n",
    "def clean_up_text_fast(text):\n",
    "    \"\"\"\n",
    "    Optimized version of clean_up_text with pre-compiled regex patterns.\n",
    "    \"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Historical / OCR quirks\n",
    "    text = text.replace('ſ', 's')  # long s\n",
    "    text = PATTERNS['vv_to_w'].sub('w', text)  # vv → w\n",
    "    text = text.replace('|', 'I')  # | → I\n",
    "    \n",
    "    # Replace digits that look like letters\n",
    "    text = PATTERNS['digit_1_to_I'].sub('I', text)\n",
    "    text = PATTERNS['digit_0_to_O'].sub('O', text)\n",
    "    text = PATTERNS['digit_5_to_S'].sub('S', text)\n",
    "    text = PATTERNS['digit_8_to_B'].sub('B', text)\n",
    "    \n",
    "    # Contraction fixes\n",
    "    text = PATTERNS['contractions'].sub(r\"'\\1\", text)\n",
    "    \n",
    "    # Hyphenation across line breaks\n",
    "    text = PATTERNS['hyphenation'].sub(r'\\1\\2', text)\n",
    "    \n",
    "    # Paragraph/spacing cleanup\n",
    "    text = PATTERNS['multiple_spaces'].sub(' ', text)\n",
    "    text = PATTERNS['multiple_newlines'].sub('\\n\\n', text)\n",
    "    text = PATTERNS['sentence_breaks'].sub(r'\\1\\n\\n\\2', text)\n",
    "    \n",
    "    # Punctuation spacing\n",
    "    text = PATTERNS['space_before_punct'].sub(r'\\1', text)\n",
    "    text = PATTERNS['space_after_punct'].sub(r'\\1 ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Test performance on a small sample\n",
    "import time\n",
    "sample_size = 1000\n",
    "sample_df = df.head(sample_size).copy()\n",
    "\n",
    "print(f\"Testing performance on {sample_size} rows...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Apply cleaning to sample\n",
    "sample_df['cleaned_ocr'] = sample_df['ocrText'].apply(clean_up_text_fast)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time for {sample_size} rows: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Estimated time for full dataset: {(end_time - start_time) * len(df) / sample_size / 60:.1f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "65ddafc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      2\u001b[39m pattern = \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(re.escape, phrases))\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Filter\u001b[39;00m\n\u001b[32m      5\u001b[39m mask = (\n\u001b[32m      6\u001b[39m     (df[\u001b[33m\"\u001b[39m\u001b[33mfile_cat\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[33m\"\u001b[39m\u001b[33mnon_application\u001b[39m\u001b[33m\"\u001b[39m) &  \u001b[38;5;66;03m# skip non-application\u001b[39;00m\n\u001b[32m      7\u001b[39m     (\n\u001b[32m      8\u001b[39m         \u001b[38;5;66;03m# check transcriptionText if present\u001b[39;00m\n\u001b[32m      9\u001b[39m         df[\u001b[33m\"\u001b[39m\u001b[33mtranscriptionText\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).str.contains(pattern, case=\u001b[38;5;28;01mFalse\u001b[39;00m, regex=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m         |\n\u001b[32m     11\u001b[39m         \u001b[38;5;66;03m# otherwise fall back to ocrText\u001b[39;00m\n\u001b[32m     12\u001b[39m         (\n\u001b[32m     13\u001b[39m             (df[\u001b[33m\"\u001b[39m\u001b[33mtranscriptionText\u001b[39m\u001b[33m\"\u001b[39m].isna() | df[\u001b[33m\"\u001b[39m\u001b[33mtranscriptionText\u001b[39m\u001b[33m\"\u001b[39m].eq(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)) &\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m             \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mocrText\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m         )\n\u001b[32m     16\u001b[39m     )\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m df_filtered = df[mask].copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pension-files/lib/python3.13/site-packages/pandas/core/strings/accessor.py:140\u001b[39m, in \u001b[36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     msg = (\n\u001b[32m    136\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with values of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minferred dtype \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m     )\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pension-files/lib/python3.13/site-packages/pandas/core/strings/accessor.py:1346\u001b[39m, in \u001b[36mStringMethods.contains\u001b[39m\u001b[34m(self, pat, case, flags, na, regex)\u001b[39m\n\u001b[32m   1338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m regex \u001b[38;5;129;01mand\u001b[39;00m re.compile(pat).groups:\n\u001b[32m   1339\u001b[39m     warnings.warn(\n\u001b[32m   1340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1342\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m   1343\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1344\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1346\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_str_contains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_result(result, fill_value=na, returns_string=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pension-files/lib/python3.13/site-packages/pandas/core/strings/object_array.py:162\u001b[39m, in \u001b[36mObjectStringArrayMixin._str_contains\u001b[39m\u001b[34m(self, pat, case, flags, na, regex)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isna(na) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(na, \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# GH#59561\u001b[39;00m\n\u001b[32m    156\u001b[39m     warnings.warn(\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAllowing a non-bool \u001b[39m\u001b[33m'\u001b[39m\u001b[33mna\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in obj.str.contains is deprecated \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand will raise in a future version.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    159\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    160\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    161\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_str_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbool\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pension-files/lib/python3.13/site-packages/pandas/core/strings/object_array.py:82\u001b[39m, in \u001b[36mObjectStringArrayMixin._str_map\u001b[39m\u001b[34m(self, f, na_value, dtype, convert)\u001b[39m\n\u001b[32m     80\u001b[39m map_convert = convert \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(mask)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     result = \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_convert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[32m     86\u001b[39m     p_err = (\n\u001b[32m     87\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m((takes)|(missing)) (?(2)from \u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+ to )?\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+ \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(?(3)required )positional arguments?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2922\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer_mask\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2959\u001b[39m, in \u001b[36mpandas._libs.lib._map_infer_mask\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pension-files/lib/python3.13/site-packages/pandas/core/strings/object_array.py:147\u001b[39m, in \u001b[36mObjectStringArrayMixin._str_contains.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    143\u001b[39m         flags |= re.IGNORECASE\n\u001b[32m    145\u001b[39m     pat = re.compile(pat, flags=flags)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     f = \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mpat\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m case:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Build one regex pattern that matches any phrase (case-insensitive)\n",
    "pattern = '|'.join(map(re.escape, phrases))\n",
    "\n",
    "# Filter\n",
    "mask = (\n",
    "    (df[\"file_cat\"] != \"non_application\") &  # skip non-application\n",
    "    (\n",
    "        # check transcriptionText if present\n",
    "        df[\"transcriptionText\"].fillna(\"\").str.contains(pattern, case=False, regex=True)\n",
    "        |\n",
    "        # otherwise fall back to ocrText\n",
    "        (\n",
    "            (df[\"transcriptionText\"].isna() | df[\"transcriptionText\"].eq(\"\")) &\n",
    "            df[\"ocrText\"].fillna(\"\").str.contains(pattern, case=False, regex=True)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "df_filtered = df[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d5e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53115, 14)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_filtered.shape\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b1f64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case-insensitive regex; make spaces flexible so \"at   the   rate\" still matches\n",
    "pattern = '|'.join(re.escape(p).replace(r'\\ ', r'\\s+') for p in phrases)\n",
    "regex = re.compile(pattern, re.IGNORECASE)\n",
    "\n",
    "def _usable_text(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    return s if s else None\n",
    "\n",
    "def extract_all_matches(row):\n",
    "    \"\"\"\n",
    "    From transcriptionText (preferred) or ocrText, split on '||'\n",
    "    and return ALL matching sections and their indices.\n",
    "    Results are '||'-joined strings (or None if no matches).\n",
    "    \"\"\"\n",
    "    trans = _usable_text(row.get(\"transcriptionText\"))\n",
    "    ocr = _usable_text(row.get(\"ocrText\"))\n",
    "    source = trans if trans is not None else ocr\n",
    "    if not source:\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "    # Split into sections; trim each\n",
    "    sections = [sec.strip() for sec in source.split(\"||\")]\n",
    "\n",
    "    matched_sections = []\n",
    "    matched_indices = []\n",
    "\n",
    "    for i, sec in enumerate(sections):\n",
    "        if regex.search(sec or \"\"):\n",
    "            matched_sections.append(sec)\n",
    "            matched_indices.append(str(i))  # keep as strings for joining\n",
    "\n",
    "    if not matched_sections:\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "    return pd.Series([\"||\".join(matched_sections), \"||\".join(matched_indices)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2d7e3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allowance_phrase_idx</th>\n",
       "      <th>allowance_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>15</td>\n",
       "      <td>it\\n21\\nBoston Massachusetts\\nOctober\\n10, 629...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>15||30||45||50</td>\n",
       "      <td>1891\\nMay 2 Bradly history\\nR\\nConnecticut 531...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>55</td>\n",
       "      <td>State of Virginia\\nto\\nanifor\\nCounty to wit:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>1||10||11||12</td>\n",
       "      <td>[LEFT PAGE, written vertically]\\n\\nRolls sent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>1</td>\n",
       "      <td>17 00402\\n℗\\nBeavertown Beaver County\\nby even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>19||23||33||42</td>\n",
       "      <td>To the Honorable the Secretary of the War Depa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>1||11</td>\n",
       "      <td>9056\\nConnecticut\\n-\\nAbner Cable\\nMonroe in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>11||19</td>\n",
       "      <td>IN REPLY REFER TO Rev. War Section 1865\\nDEPAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>2</td>\n",
       "      <td>City of Boston Massachusetts\\nJanuary 24th 183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>16</td>\n",
       "      <td>1\\n96\\nJames White a pensioner of the US stand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     allowance_phrase_idx                                   allowance_phrase\n",
       "1206                   15  it\\n21\\nBoston Massachusetts\\nOctober\\n10, 629...\n",
       "1228       15||30||45||50  1891\\nMay 2 Bradly history\\nR\\nConnecticut 531...\n",
       "1460                   55  State of Virginia\\nto\\nanifor\\nCounty to wit:\\...\n",
       "1765        1||10||11||12  [LEFT PAGE, written vertically]\\n\\nRolls sent ...\n",
       "1767                    1  17 00402\\n℗\\nBeavertown Beaver County\\nby even...\n",
       "1778       19||23||33||42  To the Honorable the Secretary of the War Depa...\n",
       "1820                1||11  9056\\nConnecticut\\n-\\nAbner Cable\\nMonroe in t...\n",
       "1827               11||19  IN REPLY REFER TO Rev. War Section 1865\\nDEPAR...\n",
       "1875                    2  City of Boston Massachusetts\\nJanuary 24th 183...\n",
       "2032                   16  1\\n96\\nJames White a pensioner of the US stand..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add columns to df_filtered\n",
    "df_filtered[[\"allowance_phrase\", \"allowance_phrase_idx\"]] = df_filtered.apply(extract_all_matches, axis=1)\n",
    "\n",
    "# (optional) quick peek\n",
    "df_filtered[[\"allowance_phrase_idx\", \"allowance_phrase\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d61ac9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allowance_phrase_idx                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 15\n",
       "allowance_phrase        it\\n21\\nBoston Massachusetts\\nOctober\\n10, 629\\nMassachusetts\\n---\\nWilliam Hendley\\nin the state of Mass\\nwas a Corporal in the regiment commanded by\\nme, for the term of\\nBrooks of the Mass\\nscribed on the Roll of Massachusetts\\nat the rate of -8- Dollars per month, to commence on\\nthe 31 of March 1818\\nertificate of Pension issued the 15 of May 1819\\nand sent to Hon John Davis\\nBoston, Massachusetts\\nArrears to 4th of March 1819\\n89.29\\nSemi-anl, all'ce ending 4 Sept 1819 48\\n---\\n11/1 $1372\\nRevolutionary claim,\\nAct 18th March, 1818.}\\nContinued\\n-\n",
       "Name: 1206, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show complete text for inspection\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df_filtered.loc[df_filtered.index[0], [\"allowance_phrase_idx\", \"allowance_phrase\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31e6cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show percentage distribution of file_cat in df_filtered\n",
    "# print(\"File category distribution in df_filtered:\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# # Get counts and percentages\n",
    "# file_cat_counts = df_filtered['file_cat'].value_counts()\n",
    "# file_cat_percentages = df_filtered['file_cat'].value_counts(normalize=True) * 100\n",
    "\n",
    "# # Create a summary dataframe\n",
    "# summary_df = pd.DataFrame({\n",
    "#     'Count': file_cat_counts,\n",
    "#     'Percentage': file_cat_percentages.round(2)\n",
    "# })\n",
    "\n",
    "# print(summary_df)\n",
    "# print(f\"\\nTotal rows: {len(df_filtered)}\")\n",
    "\n",
    "# # Also show the original distribution for comparison\n",
    "# print(\"\\n\" + \"=\" * 50)\n",
    "# print(\"For comparison - Original df file_cat distribution:\")\n",
    "# original_counts = df['file_cat'].value_counts()\n",
    "# original_percentages = df['file_cat'].value_counts(normalize=True) * 100\n",
    "\n",
    "# original_summary = pd.DataFrame({\n",
    "#     'Count': original_counts,\n",
    "#     'Percentage': original_percentages.round(2)\n",
    "# })\n",
    "# print(original_summary)\n",
    "# print(f\"Total rows in original: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "550a3c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show only percent change for each category\n",
    "# print(\"Category percent change analysis:\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# # Get counts for both datasets\n",
    "# original_counts = df['file_cat'].value_counts()\n",
    "# filtered_counts = df_filtered['file_cat'].value_counts()\n",
    "\n",
    "# # Create simple comparison\n",
    "# comparison_df = pd.DataFrame({\n",
    "#     'Original_Count': original_counts,\n",
    "#     'Filtered_Count': filtered_counts.fillna(0)\n",
    "# })\n",
    "\n",
    "# # Calculate percent change\n",
    "# comparison_df['Percent_Change'] = ((comparison_df['Filtered_Count'] - comparison_df['Original_Count']) / comparison_df['Original_Count'] * 100).round(1)\n",
    "\n",
    "# # Sort by percent change (largest decreases first)\n",
    "# comparison_df = comparison_df.sort_values('Percent_Change')\n",
    "\n",
    "# # Show only the percent change\n",
    "# # print(comparison_df[['Original_Count', 'Filtered_Count', 'Percent_Change']])\n",
    "# print(comparison_df[[ 'Percent_Change']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9510dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 30 random samples to allowance_phrase_samples_2.json\n",
      "Sample NAIDs: [196448950, 54311592, 54250294, 54779881, 54653690]...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility (optional)\n",
    "random.seed(41)\n",
    "\n",
    "# Filter to only rows that have allowance_phrase (not null/empty)\n",
    "valid_phrases = df_filtered[df_filtered['allowance_phrase'].notna() & (df_filtered['allowance_phrase'] != '')]\n",
    "\n",
    "# Get 30 random samples\n",
    "sample_size = min(30, len(valid_phrases))\n",
    "random_samples = valid_phrases.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Create the data structure for JSON\n",
    "samples_data = []\n",
    "for idx, row in random_samples.iterrows():\n",
    "    sample = {\n",
    "        \"NAID\": int(row['NAID']),\n",
    "        \"allowance_phrase\": row['allowance_phrase']\n",
    "    }\n",
    "    samples_data.append(sample)\n",
    "\n",
    "# Save to JSON file\n",
    "output_file = \"allowance_phrase_samples_2.json\"\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(samples_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(samples_data)} random samples to {output_file}\")\n",
    "print(f\"Sample NAIDs: {[sample['NAID'] for sample in samples_data[:5]]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a0479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pension-files",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
