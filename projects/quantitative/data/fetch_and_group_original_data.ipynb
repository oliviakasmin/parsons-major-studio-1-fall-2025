{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9830e8c1",
   "metadata": {},
   "source": [
    "### Fetch original data from hugging face, drop a few metadata columns, and group pension files data by NAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a4573",
   "metadata": {},
   "source": [
    "##### Fetch data from hugging face (only run once âœ…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259574ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet(\"hf://datasets/RevolutionCrossroads/nara_revolutionary_war_pension_files/nara_pension_file_pages.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d26bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe locally to avoid re-downloading\n",
    "# df.to_parquet('original_nara_pension_file_pages.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f835736",
   "metadata": {},
   "source": [
    "#### Load locally saved df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef34c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('original_nara_pension_file_pages.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns: transcriptionDate, transcriptionUserNames, transcriptionContributionCount, transcriptionID, logicalDate, ocrID, ocrUploadDate, ocrContributor\n",
    "df = df.drop(columns=['transcriptionDate', 'transcriptionUserNames', 'transcriptionContributionCount', 'transcriptionID', 'logicalDate', 'ocrID', 'ocrUploadDate', 'ocrContributor', 'variantControlNumbers', 'pdfObjectID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad467267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the title column\n",
    "print(\"Number of NaN values in title column:\", df['title'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cd068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d9e6ce",
   "metadata": {},
   "source": [
    "#### Group by NAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = '||'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by NAID to create a new df with the grouped data\n",
    "# for each row being grouped by the same NAID, concatenate the values for each row with \"||\" as a separator\n",
    "\n",
    "df_grouped = df.groupby('NAID').agg(lambda x: separator.join(x.dropna().astype(str))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the title column for new grouped df\n",
    "print(\"Number of NaN values in title column:\", df_grouped['title'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f943919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.shape\n",
    "df_grouped.head()\n",
    "df_grouped.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aba4082",
   "metadata": {},
   "source": [
    "##### remove any duplicate values from grouping by NAID in select columns including [title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_remove_duplicates(cell):\n",
    "    if not isinstance(cell, str):\n",
    "        return False\n",
    "    if not separator in cell:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def safe_remove_duplicates(cell):\n",
    "    vals = cell.split(separator)\n",
    "    \n",
    "    # Get unique values\n",
    "    unique_vals = list(set(vals))\n",
    "    \n",
    "    if len(unique_vals) == 1:\n",
    "        return unique_vals[0]\n",
    "    else:\n",
    "        return separator.join(unique_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88459ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove_duplicates = df_grouped.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove_duplicates['title'] = df_remove_duplicates['title'].apply(\n",
    "    lambda x: safe_remove_duplicates(x) if should_remove_duplicates(x) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what types of values are in the title column after applying the duplicates function\n",
    "print(\"Data types in title column after applying safe_remove_duplicates:\")\n",
    "print(df_remove_duplicates['title'].apply(type).value_counts())\n",
    "\n",
    "print(\"\\nSample values and their types:\")\n",
    "sample_values_de_duplicated = df_remove_duplicates['title'].head(10)\n",
    "for i, val in enumerate(sample_values_de_duplicated):\n",
    "    print(f\"Index {i}: '{val}' (type: {type(val)}, is NaN: {pd.isna(val)})\")\n",
    "\n",
    "print(f\"\\nNaN count after: {df_remove_duplicates['title'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103a272",
   "metadata": {},
   "source": [
    "#### remove duplicates from other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ec6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove_duplicates['pageImageType'] = df_remove_duplicates['pageImageType'].apply(\n",
    "    lambda x: safe_remove_duplicates(x) if should_remove_duplicates(x) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove_duplicates.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pension-files",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
